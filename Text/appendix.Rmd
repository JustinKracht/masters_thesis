---
output: pdf_document
---

```{r appx-setup, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
generate_figs <- FALSE
pacman::p_load(ggplot2,
               here,
               lme4,
               merTools,
               dplyr,
               tidyr,
               patchwork)

pacman::p_load_gh("crsh/papaja",
                  "benmarwick/wordcountaddin")

project_dir <- here()
results_matrix_npd <- readRDS(paste0(project_dir, 
                                     "/Data", 
                                     "/results_matrix_npd.RDS"))

# dpi sets figure size in knitted document; this doesn't control the dpi of
# saved images
dpi <- 280
generate_figs <- FALSE
```

# Regression Diagnostics

## Models 1A and 1B: Regression models predicting $\log \textrm{D}_s(\mathbf{R}_{\textrm{Sm}}, \mathbf{R}_{\textrm{Pop}})$

```{r RpopRsm-mod-fit, echo = FALSE, eval = FALSE}
# Import simulation data
sim_data <- readRDS(here("Data", "results_matrix.RDS"))
sim_data <- sim_data %>% 
  dplyr::filter(npd == TRUE, # only keep npd matrices
                !is.na(distance_Rpop_Rsm)) %>% # remove missing values
  select(id:npd, smoothing_method, distance_Rpop_Rsm) %>%
  distinct() # keep only unique observations of smoothed matrices

# Standardize all numeric predictors
sim_data <- mutate_at(sim_data,
                      .vars = c("subjects_per_item", "items_per_factor", 
                                "factors", "factor_loading", "model_error"),
                      .funs = function(x) as.vector(scale(x)))

# Fit the linear mixed effects model with a random intercept for each NPD
# tetrachoric correlation matrix
RpopRsm_model <- lme4::lmer(
  log(distance_Rpop_Rsm) ~ (subjects_per_item + items_per_factor + 
                              factors + factor_loading + model_error + 
                              smoothing_method)^2 + (1|id),
  data = sim_data
)
```

```{r RpopRsm-diagnostics, echo = FALSE, warning = FALSE, message = FALSE}
if (generate_figs) {
  # Load the models
  RpopRsm_model_linear <- readRDS(here("Data", "RpopRsm_model.RDS"))
  RpopRsm_model_poly <- readRDS(here("Data", "RpopRsm_model_poly.RDS"))
  
  # Linear model ----
  resid_vals_linear <- resid(RpopRsm_model_linear, type = "response")
  fitted_vals_linear <- fitted(RpopRsm_model_linear)
  RpopRsm_diagnostic_linear <- data.frame(fitted_vals = fitted_vals_linear,
                                          resid_vals  = resid_vals_linear,
                                          model_type = "Linear Model")
  ranef_vals_linear <- ranef(RpopRsm_model_linear, drop = TRUE, condVar = FALSE)$id
  
  # Polynomial model ----
  resid_vals_poly <- resid(RpopRsm_model_poly, type = "response")
  fitted_vals_poly <- fitted(RpopRsm_model_poly)
  RpopRsm_diagnostic_poly <- data.frame(fitted_vals = fitted_vals_poly,
                                        resid_vals  = resid_vals_poly,
                                        model_type = "Polynomial Model")
  ranef_vals_poly <- ranef(RpopRsm_model_poly, drop = TRUE, condVar = FALSE)$id
  
  # Combine linear and polynomial results
  RpopRsm_diagnostic <- rbind(RpopRsm_diagnostic_linear,
                              RpopRsm_diagnostic_poly)
  
  # Create data for residual and random effect QQ plots
  # QQ plot data
  RpopRsm_qq_linear <- data.frame(
    sample_quantile = RpopRsm_diagnostic_linear$resid_vals[order(RpopRsm_diagnostic_linear$resid_vals)],
    theoretical_quantile = qnorm(ppoints(length(RpopRsm_diagnostic_linear$resid_vals))),
    model_type = "Linear Model"
  )
  
  RpopRsm_qq_poly <- data.frame(
    sample_quantile = RpopRsm_diagnostic_poly$resid_vals[order(RpopRsm_diagnostic_poly$resid_vals)],
    theoretical_quantile = qnorm(ppoints(length(RpopRsm_diagnostic_poly$resid_vals))),
    model_type = "Polynomial Model"
  )
  
  RpopRsm_qq <- rbind(RpopRsm_qq_linear,
                      RpopRsm_qq_poly)
  # Random effect data
  RpopRsm_random_effects <- data.frame(
    random_effect = c(ranef_vals_linear[order(ranef_vals_linear)],
                      ranef_vals_poly[order(ranef_vals_poly)]),
    theoretical_quantile = c(qnorm(ppoints(length(ranef_vals_linear))),
                             qnorm(ppoints(length(ranef_vals_poly)))),
    model_type = rep(c("Linear Model",
                     "Polynomial Model"),
                     c(length(ranef_vals_linear),
                       length(ranef_vals_poly)))
  )
  
  # Create diagnostic plots
  resid_vs_fitted <- ggplot(RpopRsm_diagnostic, 
                               aes(x = fitted_vals, y = resid_vals)) +
  geom_hex(bins = 100) +
  scale_fill_continuous(type = "viridis") +
  facet_grid(. ~ model_type) +
  coord_cartesian(ylim = c(-.5, .4)) +
  labs(x = "Fitted value",
       y = "Residual")
  
  resid_qq <- ggplot(RpopRsm_qq, aes(x = theoretical_quantile,
                                     y = sample_quantile)) +
    geom_hex(bins = 75) +
    facet_grid(. ~ model_type) +
    scale_x_continuous(breaks = c(-2.5, 0, 2.5)) +
    scale_fill_continuous(type = "viridis") +
    labs(y = "Residual",
         x = "Theoretical Quantile")
  
  ranef_qq <- ggplot(RpopRsm_random_effects,
                     aes(x = theoretical_quantile,
                         y = random_effect)) +
    geom_hex(bins = 75) +
    facet_grid(. ~ model_type) +
    scale_fill_continuous(type = "viridis") +
    labs(y = "Random Effect",
         x = "Theoretical Quantile")
    
    # Combine and save plots ----
    ggsave(filename = "RpopRsm_resid_vs_fitted.png",
           path = here("Text", "figs"),
           plot = resid_vs_fitted,
           dpi = "retina",
           width = 12,
           height = 6,
           scale = .55)
    
    ggsave(filename = "RpopRsm_resid_qq.png",
           path = here("Text", "figs"),
           plot = resid_qq,
           dpi = "retina",
           width = 12,
           height = 6,
           scale = .55)
    
    ggsave(filename = "RpopRsm_ranef_qq.png",
           path = here("Text", "figs"),
           plot = ranef_qq,
           dpi = "retina",
           width = 12,
           height = 6,
           scale = .55)
}
```

Models 1A and 1B were a linear mixed-effects models predicting the (log) scaled distance between the smoothed and model-implied population correlation matrix and was fit using the R *lme4* package (Version 1.1.23; Bates, Mächler, Bolker, & Walker, 2015). Model 1A was a linear model fit using all simulation variables and their interactions. In Model 1B, second-degree polynomial terms were added for number of factors, number of subjects per item, factor loading, and model error. Diagnostic plots showing standardized residuals plotted against fitted values for both models, quantile-quantile (QQ) plots of the residuals, and QQ plots for the random intercept terms are shown in Figures \@ref(fig:residuals-vs-fitted-RpopRsm), \@ref(fig:qq-plot-RpopRsm), and \@ref(fig:qq-plot-randInt-RpopRsm) respectively. These plots show that some assumptions of the linear mixed-effects model seem to have been violated for Models 1A and 1B, even after applying a log-transformation to the response variable.

```{r qq-plot-RpopRsm, fig.width = 4.5, echo = FALSE, fig.cap = "Quantile-quantile plot of residuals for Models 1A and 1B.", fig.align = "center"}
knitr::include_graphics(
  path = here("Text", "figs", "RpopRsm_resid_qq.png"),
  dpi = dpi
)
```

```{r qq-plot-randInt-RpopRsm, fig.width = 4.5, echo = FALSE, fig.cap = "Quantile-quantile plot of random intercept terms for Models 1A and 1B.", fig.align = "center"}
knitr::include_graphics(
  path = here("Text", "figs", "RpopRsm_ranef_qq.png"),
  dpi = dpi
)
```

Figure \@ref(fig:residuals-vs-fitted-RpopRsm) shows that the variance of the residuals was not constant over the range of fitted values for both the linear and polynomial models. In particular, for both models there was little variation near the edges of the range of fitted values and a large amount of variation near the center of the distribution of fitted values. Therefore, the homoscedasticity assumption seemed to have been violated. Moreover, Figure \@ref(fig:qq-plot-RpopRsm) shows that the assumption of normally-distributed errors was also likely violated. In particular, Figure \@ref(fig:qq-plot-RpopRsm) shows that the distributions of residuals (for both models) had heavy tails and had a slight positive skew (Model 1A: kurtosis = 16.25, skew = 0.60; Model 1B: kurtosis = 18.61, skew = 0.23). Finally, Figure \@ref(fig:qq-plot-randInt-RpopRsm) shows that the random effects (random intercepts) were not normally-distributed for either the linear or polynomial model (Model 1A: kurtosis = 5.52, skew = 1.52; Model 1B: kurtosis = 10.33, skew = 0.59). To address these violations of the model assumptions, I first attempted to fit a robust mixed-effects model using `rlmer()` function in the R *robustlmm* package (Version 2.3; Koller, 2016). Unfortunately, the data set was too large for the `rlmer()` function to handle. I also tried a more complex transformation of the dependent variable (using a Box-Cox power transformation; Box & Cox, 1964), but it produced no discernible benefit compared to a log transformation.

```{r residuals-vs-fitted-RpopRsm, fig.width = 2, echo = FALSE, fig.cap = "Residuals plotted against fitted values for Models 1A and 1B.", fig.align = "center"}
knitr::include_graphics(
  path = here("Text", "figs", "RpopRsm_resid_vs_fitted.png"),
  dpi = dpi
)
```

The apparent violations of the assumptions of the mixed-effects model were concerning. However, inference for the fixed effects in mixed-effects models seems to be somewhat robust to these violations. In particular, Jacqmin-Gadda, Sibillot, Proust, Molina, & Thiébaut (2007) showed that inference for fixed effects is robust for non-Gaussian and heteroscedastic errors. Moreover,  Jacqmin-Gadda et al. (2007) cited several studies indicating that inference for fixed effects is also robust to non-Gaussian random effects  (Butler & Louis, 1992; Verbeke & Lesaffre, 1997; Zhang & Davidian, 2001). Finally, the purpose of the present analysis was to obtain estimates of the fixed effects of matrix smoothing methods (and the interactions between smoothing methods and the other design factors) on population correlation matrix recovery. Neither $p$-values nor confidence intervals were of primary concern. Therefore, the apparent violation of some model assumptions likely did not affect the main results of this study.

## Models 2A and 2B: Regression models predicting $\log \textrm{RMSE}(\mathbf{F}, \hat{\mathbf{F}})$

```{r loadings-mod-fit, eval = FALSE, echo = FALSE}
# Import simulation data
sim_data <- readRDS(here("Data", "results_matrix.RDS"))
sim_data <- sim_data %>% 
  dplyr::filter(npd == TRUE, # only keep npd matrices
                !is.na(loading_rmsd), # remove obs. with missing values
                fa_convergence == TRUE) %>% # only keep obs. where FA converged
  select(id:npd, smoothing_method, fa_method, loading_rmsd)

# Standardize all numeric predictors
sim_data <- mutate_at(sim_data,
                      .vars = c("subjects_per_item", "items_per_factor", 
                                "factors", "factor_loading", "model_error"),
                      .funs = function(x) as.vector(scale(x)))

# Fit the linear mixed effects model with a random intercept for each NPD
# tetrachoric correlation matrix
loading_model <- lme4::lmer(
  log(loading_rmsd) ~ (subjects_per_item + items_per_factor + 
                         factors + factor_loading + model_error + 
                         smoothing_method + fa_method)^2 + (1|id),
  data = sim_data
)
```

```{r loading_recovery_diagnostics}
if (generate_figs) {
  # Load the models
  loading_model_linear <- readRDS(here("Data", "loading_model.RDS"))
  loading_model_poly <- readRDS(here("Data", "loading_model_poly.RDS"))
  
  # Linear model ----
  resid_vals_linear <- resid(loading_model_linear, type = "response")
  fitted_vals_linear <- fitted(loading_model_linear)
  loading_diagnostic_linear <- data.frame(fitted_vals = fitted_vals_linear,
                                          resid_vals  = resid_vals_linear,
                                          model_type = "Linear Model")
  ranef_vals_linear <- ranef(loading_model_linear, drop = TRUE, condVar = FALSE)$id
  
  # Polynomial model ----
  resid_vals_poly <- resid(loading_model_poly, type = "response")
  fitted_vals_poly <- fitted(loading_model_poly)
  loading_diagnostic_poly <- data.frame(fitted_vals = fitted_vals_poly,
                                        resid_vals  = resid_vals_poly,
                                        model_type = "Polynomial Model")
  ranef_vals_poly <- ranef(loading_model_poly, drop = TRUE, condVar = FALSE)$id
  
  # Combine linear and polynomial results
  loading_diagnostic <- rbind(loading_diagnostic_linear,
                              loading_diagnostic_poly)
  
  # Create data for residual and random effect QQ plots
  # QQ plot data
  loading_qq_linear <- data.frame(
    sample_quantile = loading_diagnostic_linear$resid_vals[order(loading_diagnostic_linear$resid_vals)],
    theoretical_quantile = qnorm(ppoints(length(loading_diagnostic_linear$resid_vals))),
    model_type = "Linear Model"
  )
  
  loading_qq_poly <- data.frame(
    sample_quantile = loading_diagnostic_poly$resid_vals[order(loading_diagnostic_poly$resid_vals)],
    theoretical_quantile = qnorm(ppoints(length(loading_diagnostic_poly$resid_vals))),
    model_type = "Polynomial Model"
  )
  
  loading_qq <- rbind(loading_qq_linear,
                      loading_qq_poly)
  # Random effect data
  loading_random_effects <- data.frame(
    random_effect = c(ranef_vals_linear[order(ranef_vals_linear)],
                      ranef_vals_poly[order(ranef_vals_poly)]),
    theoretical_quantile = c(qnorm(ppoints(length(ranef_vals_linear))),
                             qnorm(ppoints(length(ranef_vals_poly)))),
    model_type = rep(c("Linear Model",
                     "Polynomial Model"),
                     c(length(ranef_vals_linear),
                       length(ranef_vals_poly)))
  )
  
  # Create diagnostic plots
  resid_vs_fitted <- ggplot(loading_diagnostic, 
                            aes(x = fitted_vals, y = resid_vals)) +
    geom_hex(bins = 100) +
    scale_fill_continuous(type = "viridis") +
    facet_grid(. ~ model_type) +
    labs(x = "Fitted value",
         y = "Residual")
  
  resid_qq <- ggplot(loading_qq, aes(x = theoretical_quantile,
                                     y = sample_quantile)) +
    geom_hex(bins = 75) +
    facet_grid(. ~ model_type) +
    scale_fill_continuous(type = "viridis") +
    labs(y = "Residual",
         x = "Theoretical Quantile")
  
  ranef_qq <- ggplot(loading_random_effects,
                     aes(x = theoretical_quantile,
                         y = random_effect)) +
    geom_hex(bins = 75) +
    facet_grid(. ~ model_type) +
    scale_fill_continuous(type = "viridis") +
    labs(y = "Random Effect",
         x = "Theoretical Quantile")
    
    # Combine and save plots ----
    ggsave(filename = "loading_resid_vs_fitted.png",
           path = here("Text", "figs"),
           plot = resid_vs_fitted,
           dpi = "retina",
           width = 12,
           height = 6,
           scale = .55)
    
    ggsave(filename = "loading_resid_qq.png",
           path = here("Text", "figs"),
           plot = resid_qq,
           dpi = "retina",
           width = 12,
           height = 6,
           scale = .55)
    
    ggsave(filename = "loading_ranef_qq.png",
           path = here("Text", "figs"),
           plot = ranef_qq,
           dpi = "retina",
           width = 12,
           height = 6,
           scale = .55)
}
```

Models 2A and 2B were mixed-effects models predicting $\log \textrm{RMSE}(\mathbf{F}, \hat{\mathbf{F}})$ and fit using the R *lme4* package (Bates, Mächler, Bolker, & Walker, 2015). Model 2A was a linear model fit using all simulation variables and their interactions. In Model 2B, second-degree polynomial terms were added for number of factors, number of subjects per item, factor loading, and model error. As with Models 1A and 1B, diagnostic plots showing standardized residuals plotted against fitted values for both models, QQ plots for the residuals, and QQ plots for the random intercept terms are shown in Figures \@ref(fig:residuals-vs-fitted-RpopRsm), \@ref(fig:qq-plot-loading-recovery), and \@ref(fig:qq-plot-randInt-loadings) respectively.

```{r residuals-vs-fitted-loading-recovery, fig.width = 5.5, echo = FALSE, fig.cap = "Residuals plotted against fitted values for Models 2A and 2B.", fig.align = "center"}
knitr::include_graphics(
  path = here("Text", "figs", "loading_resid_vs_fitted.png"),
  dpi = dpi
)
```

```{r qq-plot-loading-recovery, fig.width = 4, echo = FALSE, fig.cap = "Quantile-quantile plot of residuals for Models 2A and 2B.", fig.align = "center"}
knitr::include_graphics(
  path = here("Text", "figs", "loading_resid_qq.png"),
  dpi = dpi
)
```

```{r qq-plot-randInt-loadings, fig.width = 4, echo = FALSE, fig.cap = "Quantile-quantile plot of random intercept terms for Models 2A and 2B.", fig.align = "center"}
knitr::include_graphics(
  path = here("Text", "figs", "loading_ranef_qq.png"),
  dpi = dpi
)
```

These plots indicate many of the same issues in Models 2A and 2B as were seen for Models 1A and 1B. First, Figure \@ref(fig:residuals-vs-fitted-RpopRsm) shows clear evidence of non-homogeneous conditional error variance for both the linear and polynomial models. Specifically, the residual variance seemed generally to be larger for larger fitted values. Second, Figure \@ref(fig:qq-plot-loading-recovery) shows that the distribution of residuals for both models was non-normal and similar to the distributions of the residuals from Model 1A and 1B (i.e., positively-skewed and having heavy tails). Finally, Figure \@ref(fig:qq-plot-randInt-loadings) shows that the estimated random effects were likewise not normally-distributed. The distribution of random intercepts was positively-skewed with heavy tails. Alternative transformations of the dependent variable were tried but did not seem to improve model fit compared to a log transformation. As with Model 1, these violations of the model assumptions are somewhat concerning and indicate that the estimated parameters---the estimated standard errors, in particular---should be treated with some degree of skepticism. However, the main results of the study are unlikely to have been affected greatly by these violations of the model assumptions.
